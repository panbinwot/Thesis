{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reseach Topic: Predict Wage with Machline Methods\n",
    "## What am I doing ?\n",
    "I have no idea.\n",
    "\n",
    "## Data\n",
    "The source of data is NLSY97. The portal can be accessed from [here](https://www.nlsinfo.org/investigator/pages/search.jsp?s=NLSY97). The data set is pre-cleaned by STATA with around 4500 obervations each year from 2. Features include age, year of experience, gender, schooling, race, marital status, industry, region(not yet!!). \n",
    "\n",
    "## Run some models\n",
    "Bofore running anything, we split the data into training set, validation set, test set. <br/> I am preparing to do the following models:\n",
    "- Linear model (mincer equations)\n",
    "- Trees and Forests\n",
    "- Neural Nets\n",
    "\n",
    "The performences of models will be compared in accuracy and R-square\n",
    "\n",
    "## Further thoughts\n",
    "What can we do besides running those well-defined models on a dataset and seeing some results we already know.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's get started :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # turn off warnings a bit\n",
    "\n",
    "'''Preprocessing Steps\n",
    "'''\n",
    "data_path = './data/mincer.xlsx'\n",
    "#dat.describe(include=\"all\")\n",
    "\n",
    "dat = pd.read_excel(data_path)\n",
    "train, test =  train_test_split(dat, test_size = 0.25, random_state = 12)\n",
    "train_y, train_X, test_y, test_X = train['lnwage'], train.iloc[:,3:6], test['lnwage'], test.iloc[:,3:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Linear Model (Mincer Equation)\n",
    "It is a panel data regression using random effect model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3: Neural Nets\n",
    "Use the most basic model, multilayer perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31521 samples, validate on 10508 samples\n",
      "Epoch 1/5\n",
      "31521/31521 [==============================] - 5s 172us/step - loss: 200.5209 - val_loss: 21.6564\n",
      "Epoch 2/5\n",
      "31521/31521 [==============================] - 6s 178us/step - loss: 23.2238 - val_loss: 21.6562\n",
      "Epoch 3/5\n",
      "31521/31521 [==============================] - 6s 176us/step - loss: 23.2234 - val_loss: 21.6645\n",
      "Epoch 4/5\n",
      "31521/31521 [==============================] - 6s 178us/step - loss: 23.2198 - val_loss: 21.6769\n",
      "Epoch 5/5\n",
      "31521/31521 [==============================] - 6s 176us/step - loss: 23.2207 - val_loss: 21.6548\n",
      "avg. house price: $2.58, std house price: $0.66\n",
      "mean: 21.65%, std: 54.78%\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import adam\n",
    "import argparse\n",
    "import locale\n",
    "import os\n",
    "\n",
    "def create_mlp(dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=dim, activation=\"relu\"))\n",
    "    model.add(Dense(4, activation=\"relu\"))\n",
    "    model.add(Dense(4, activation=\"relu\"))\n",
    "    model.add(Dense(4, activation=\"relu\"))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    return model\n",
    "\n",
    "model = create_mlp(train_X.shape[1])\n",
    "opt =  adam(lr = 1e-3, decay = 1e-3 / 200)\n",
    "model.compile(loss = \"mean_absolute_percentage_error\", optimizer = opt)\n",
    "model.fit(train_X, train_y, validation_data = (test_X, test_y), epochs =5, batch_size = 8)\n",
    "preds = model.predict(test_X)\n",
    "\n",
    "diff = preds.flatten() - test_y\n",
    "percentDiff = (diff / test_y) * 100\n",
    "absPercentDiff = np.abs(percentDiff)\n",
    " \n",
    "\n",
    "mean = np.mean(absPercentDiff)\n",
    "std = np.std(absPercentDiff)\n",
    " \n",
    "# finally, show some statistics on our model\n",
    "print(\"mean: {:.2f}%, std: {:.2f}%\".format(mean, std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
